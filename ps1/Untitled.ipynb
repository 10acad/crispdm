{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project: Data Minining Project for a non-profit organisation `UCOUNT`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## The CRISP-DM Framework\n",
    "\n",
    "The CRISP-DM methodology provides a structured approach to planning a data mining project. It is a robust and well-proven methodology. \n",
    "\n",
    "- Business understanding (BU): Determine Business Objectives, Assess Situation, Determine Data Mining Goals, Produce Project Plan\n",
    "\n",
    "- Data understanding (DU): Collect Initial Data, Describe Data, Explore Data, Verify Data Quality\n",
    "\n",
    "- Data preparation (DP): Select Data, Clean Data, Construct Data, Integrate Data\n",
    "\n",
    "- Modeling (M): Select modeling technique, Generate Test Design, Build Model, Assess Model\n",
    "\n",
    "- Evaluation (E): Evaluate Results, Review Process, Determine Next Steps\n",
    "\n",
    "- Deployment (D): Plan Deployment, Plan Monitoring and Maintenance, Produce Final Report, Review Project\n",
    "\n",
    "References: \n",
    "1. [What is the CRISP-DM methodology?](https://www.sv-europe.com/crisp-dm-methodology/)\n",
    "\n",
    "2. [Introduction to CRISP DM Framework for Data Science and Machine Learning](https://www.linkedin.com/pulse/chapter-1-introduction-crisp-dm-framework-data-science-anshul-roy/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Role\n",
    "All of the tasks you are asked to do in this course assumes that you are leading a data science group for a non-profit (fake) company called UCOUNT (yoUr CONTribution). \n",
    "\n",
    "As a non-profit organisation, UCOUNT's main income is donation. Moreover, for some of the smaller projects, UCOUNT uses the Kickstart and other crowd funding platforms to raise funding. \n",
    "\n",
    "As data science group leader at UCOUNT, you are tasked to advise the marketing department such that they run an effective donation and kickstart campaigns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sets\n",
    "You have two sets of data at your disposal. \n",
    "\n",
    "1. The first one is a collection of crowd funding campaigns performed in the past by different people and organisations at the [Kickstarter website](https://www.kickstarter.com/). The data is obtained using web scraper robots run by [webrobots](https://webrobots.io/kickstarter-datasets/). The bots crawled all Kickstarter projects and collect data which are then dumped in CSV format.\n",
    "\n",
    "   You can download Kickstarter data set here: [kickstarter-cleaned.csv](https://github.com/flavianh/kickstarter-dash/blob/master/kickstarter-cleaned.csv)\n",
    "   \n",
    "   You will use this data to understand the important features of successful crowd funding campaigns. For example what are the common characteristics of successful campaigns?\n",
    "\n",
    "2. The second data is a Census Income Data Set, which comes from [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Census+Income). The datset was donated by Ron Kohavi and Barry Becker, after being published in the article _\"Scaling Up the Accuracy of Naive-Bayes Classifiers: A Decision-Tree Hybrid\"_. You can find the article by Ron Kohavi [online](https://www.aaai.org/Papers/KDD/1996/KDD96-033.pdf).\n",
    "\n",
    "   You can download Census Income Data Set data here: [census-income-1996.csv](s3://10ac-courses-data/csv/census-income-1996.csv)\n",
    "    \n",
    "   You will use this data set to predict the annual income of a target donor. Understanding an individual's income can help a non-profit company like UCOUNT better understand how large of a donation to request, or whether or not they should reach out to begin with.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scale: 1 (no experience), 2(have a few experience)   3 (reasonable), 5 (ok), 8 (very good), 10 (excellent)\n",
    "\n",
    "\n",
    "What do you expect to learn from carrying out this project?\n",
    "\n",
    "What do you expect to be your main challenge to carry out this project?\n",
    "\n",
    "How do you rate your confidence level understanding data science projects and their business values?\n",
    "\n",
    "How do you rate your skill of data handling using python Data Frame?\n",
    "\n",
    "How do you rate your skill of python programming?\n",
    "\n",
    "How do you rate your skill of working with large data (>10000 raws)?\n",
    "\n",
    "How do you rate your skill of plotting in Python?\n",
    "\n",
    "How do you rate your skill of producing quality plots in Python?\n",
    "\n",
    "How do you rate your blog writing skill i.e to describe clearly the important details of your data science project such that other students can reproduce the same result?\n",
    "\n",
    "How do you rate your ability to summarise the important insights you obtained from a data analysis project to stake holders (e.g. your boss, marketing departments,  etc.)?\n",
    "\n",
    "How do you rate your skill of choosing approperiate loss functions to your project?\n",
    "\n",
    "How do you rate your understanding of the precision-recall curve, ROC curve, and other metrics commonly used to access the performance of data science algorithms?\n",
    "\n",
    "How do you rate your understanding of False Positives, False Negatives, True Positives, True Negatives?\n",
    "\n",
    "How do you rate your data cleaning skill such as data normalization, feature enginering, filling missing values?\n",
    "\n",
    "How do you rate your understanding of concepts such as classification, regressing, clustering, dimensionality reduction, segmentation, detection?\n",
    "\n",
    "How do you rate your knowledge of common algorithms used for regressing analysis?\n",
    "\n",
    "How do you rate your knowledge of common algorithms used for clustring analysis?\n",
    "\n",
    "How do you rate your knowledge of common algorithms used for classification analysis?\n",
    "\n",
    "How do you rate your skill of using GitHub or other git based platforms?\n",
    "\n",
    "How do you rate your skill of using dockers?\n",
    "\n",
    "How do you rate your skill of using jupyter notebook?\n",
    "\n",
    "How do you rate your engagement to the broader data science community using blogs, social media, local meetups and workshops? \n",
    "\n",
    "How do you rate your skill in reading and writing data from SQL data bases?\n",
    "\n",
    "How do you rate your data science skill level?\n",
    "\n",
    "\n",
    "At the end of each phase of the project, you are required to write a medium blog or a wiki page explaning your approach to the problem and the lessons you learnt in the process. Please take note (for example inside the jupyter notebook) while working on the project. This will help you write blogs with little effort. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "How Many columns have Data 1: Kickstart web scrapped?\n",
    "    Use python to load the csv data and could the number of columns\n",
    "    *14*\n",
    "    \n",
    "    Data 1: Kickstart web scrapped \n",
    "\n",
    "Data 2: Census Income Data Set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
